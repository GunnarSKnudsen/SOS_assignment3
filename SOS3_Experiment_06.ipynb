{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32fab46a",
   "metadata": {},
   "source": [
    "188.413 Self-Organising Systems\n",
    "# Exercise 3: SOM Evaluation Report - Experiment 06\n",
    "\n",
    "**Authors:**\n",
    "* Gunnar Sjúrðarson Knudsen, 12028205\n",
    "* Michael Ferdinand Moser, 01123077\n",
    "* Magnus Wagner, 12034922\n",
    "\n",
    "## Goal of this notebook\n",
    "**6) Analyze different scalings:**\n",
    "- Train a „regular“ SOM with obviously wrongly scaled data\n",
    "- Analyse cluster structure, quantization errors, topology violations. In how far does this map differ from the maps analyzed above?\n",
    "- **Describe and compare the structures found** (providing detailed info on visualizations and parameters\n",
    "\n",
    "## Comments\n",
    "As this is the only task that isn't about the parameters of the SOM, but on the preprocessing step, we will NOT be using the preprocessed data here.\n",
    "Instead we fetch the data similarly to how it was done in the preprocessing notebook, and then create a function that will preprocess dependant on the relevant scaler\n",
    "\n",
    "## Sources:\n",
    "* https://github.com/smnishko/SOMToolbox/\n",
    "* http://www.ifs.tuwien.ac.at/dm/somtoolbox/\n",
    "* https://somoclu.readthedocs.io/en/stable/example.html\n",
    "* READ THIS: https://github.com/JustGlowing/minisom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6114e1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Libraries, constants and other stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862dedd1",
   "metadata": {},
   "source": [
    "### Constants\n",
    "Mainly filename, so that SOM results get stored separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb898cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DESCRIPTION = 'Experiment_06'\n",
    "EXPERIMENT_DATA_FOLDER = 'experiment_results/experiment_06'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ea3026",
   "metadata": {},
   "source": [
    "### SOM Parameters\n",
    "Only the ones that are held consistant for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43480630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization and training\n",
    "RANDOM_SEED = 0\n",
    "N_NEURONS = 30                     # int: x dimension of the SOM\n",
    "M_NEURONS = 30                     # int: y dimension of the SOM\n",
    "SIGMA = N_NEURONS/4                # Spread of the neighborhood function, needs to be adequate to the dimensions of the map.\n",
    "LEARNING_RATE = 0.7                # initial learning rate\n",
    "TOPOLOGY = 'rectangular'           #  'rectangular', 'hexagonal'\n",
    "ACTIVATION_DISTANCE = 'euclidean'  # 'euclidean', 'cosine', 'manhattan', 'chebyshev'\n",
    "NEIGHBORHOOD_FUNCTION = 'gaussian' # 'gaussian', 'mexican_hat', 'bubble', 'triangle'\n",
    "\n",
    "NUM_ITERATIONS = 50000\n",
    "RANDOM_ORDER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddfa2e6",
   "metadata": {},
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbe6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dataset selection\n",
    "import openml\n",
    "from openml.datasets import edit_dataset, fork_dataset, get_dataset\n",
    "\n",
    "# SOM Helpers\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "## ML stuff\n",
    "from sklearn import datasets, preprocessing\n",
    "\n",
    "# SOM stuff\n",
    "from somtoolbox import SOMToolbox\n",
    "from SOMToolBox_Parse import SOMToolBox_Parse\n",
    "from minisom import MiniSom    \n",
    "\n",
    "# More som stuff\n",
    "import somoclu\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.io import export_png\n",
    "\n",
    "# Methods used for this experiment\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbed02c",
   "metadata": {},
   "source": [
    "### Read in preprocessed data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5da4442",
   "metadata": {},
   "source": [
    "with open('data/processed_data_Sampled.pkl', 'rb') as f:\n",
    "    target, label_names, data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714629d",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0eb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "did = 1497\n",
    "# Download dataset\n",
    "dataset = openml.datasets.get_dataset(did)\n",
    "\n",
    "# Create datafame of the data, and show how it looks\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(dataset_format=\"array\"\n",
    "                                                                , target=dataset.default_target_attribute\n",
    "                                                               )\n",
    "df = pd.DataFrame(X, columns= attribute_names)\n",
    "df[\"class\"] = y\n",
    "display(df)\n",
    "\n",
    "category = df.select_dtypes(include='object')\n",
    "categorial_columns = category.columns\n",
    "numerical = df.select_dtypes(exclude='object')\n",
    "numerical_columns = numerical.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96bad0",
   "metadata": {},
   "source": [
    "### Define functions for preprocessing, training, and visualizing each experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d884b",
   "metadata": {},
   "source": [
    "#### Preprocess\n",
    "Ensures that each step is done in the same method, with except of the scaler /sampler that is being tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3514175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df, description, scaler = None, sampler = None, verbose = True):\n",
    "    # Scale\n",
    "    if scaler is not None:\n",
    "        df.loc[:, df.columns != 'class'] = scaler.fit_transform(df.loc[:, df.columns != 'class'])\n",
    "    \n",
    "    # Visualize results\n",
    "    if verbose:\n",
    "        f = plt.figure(figsize=(12, 8), dpi=600)\n",
    "        plt.title('Distribution of Columns', color='black')\n",
    "\n",
    "        df.plot(kind=\"kde\",  ax=f.gca())\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "        plt.savefig(f\"{EXPERIMENT_DATA_FOLDER}/KDE_{description}.png\")\n",
    "        plt.show()\n",
    "\n",
    "        f = plt.figure(figsize=(12, 8), dpi=600)\n",
    "        plt.title('Distribution of Columns', color='black')\n",
    "\n",
    "        df.plot(kind=\"box\",  ax=f.gca())\n",
    "        plt.savefig(f\"{EXPERIMENT_DATA_FOLDER}/boxplot_{description}.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    ### Restructure to MiniSom format\n",
    "    # Features\n",
    "    data = df[df.columns[:-1]]\n",
    "    data = data.values\n",
    "\n",
    "    # Target\n",
    "    target = df['class']\n",
    "\n",
    "    # Check if this re-encoding is correct\n",
    "    label_names = {0: 'Move-Forward'\n",
    "                 , 1: 'Slight-Right-Turn'\n",
    "                 , 2: 'Sharp-Right-Turn'\n",
    "                 , 3: 'Slight-Left-Turn'\n",
    "                  }\n",
    "    # Do sampling\n",
    "    if sampler is not None:\n",
    "        data, target = sampler.fit_resample(data,target)\n",
    "        \n",
    "    return target, label_names, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d6b17-b386-4f17-8a0f-5601110e5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def javafy_data(target, label_names, data, description):\n",
    "    #### Input Vector\n",
    "    PRE_INPUT = f\"$TYPE vec\\n$XDIM {len(target)}\\n$YDIM 1\\n$VEC_DIM 24\\n\"\n",
    "    folder_name = f\"{description}\"\n",
    "    PATH = f'./java_folder/experiment_06/{folder_name}/input.vec'\n",
    "    \n",
    "    if not os.path.exists(f'./java_folder/experiment_06/{folder_name}'):\n",
    "        os.makedirs(f'./java_folder/experiment_06/{folder_name}')\n",
    "\n",
    "    data_concatted = np.concatenate((data.astype(np.float16),np.arange(1,len(data)+1).reshape(-1,1)),axis=1)\n",
    "\n",
    "    np.savetxt(PATH, data_concatted,delimiter=\" \", fmt = '%1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %1.6f %i')\n",
    "\n",
    "    tmp = open(PATH,mode=\"r\").read()\n",
    "\n",
    "    with open(PATH, 'w') as f:\n",
    "       f.write(PRE_INPUT+tmp)\n",
    "    \n",
    "    #### Template\n",
    "    PATH = f'./java_folder/experiment_06/{folder_name}/template.tv'\n",
    "    template =  f'$TYPE template\\n$XDIM 2\\n$YDIM {len(target)}\\n$VEC_DIM 24\\n0 V1\\n1 V2\\n2 V3\\n3 V4\\n4 V5\\n5 V6\\n6 V7\\n7 V8\\n8 V9\\n9 V10\\n10 V11\\n11 V12\\n12 V13\\n13 V14\\n14 V15\\n15 V16\\n16 V17\\n17 V18\\n18 V19\\n19 V20\\n20 V21\\n21 V22\\n22 V23\\n23 V24'\n",
    "    with open(PATH, 'w') as f:\n",
    "       f.write(template)\n",
    "    \n",
    "    #### Class info\n",
    "    PATH = f'./java_folder/experiment_06/{folder_name}/class_info.cls'\n",
    "    header =  f'$TYPE class_information\\n$NUM_CLASSES 4\\n$CLASS_NAMES Move_Forward Slight_Right_Turn Sharp_Right_Turn Slight_Left_turn\\n$XDIM 2\\n$YDIM {len(target)}\\n'\n",
    "\n",
    "    target_new = target.copy(deep=True)\n",
    "    target_new = pd.DataFrame(target_new)\n",
    "    target_new[\"index\"]=np.arange(1,len(target)+1)\n",
    "    target_new=target_new.set_index(\"index\")\n",
    "\n",
    "    with open(PATH, 'w') as f:\n",
    "       f.write(header)\n",
    "    target_new.to_csv(PATH, header=None, index=True, sep=' ', mode='a')\n",
    "    \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7be26",
   "metadata": {},
   "source": [
    "#### Train SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_som(_df, _description, _scaler = None, _sampler = None, _verbose = True):\n",
    "    \n",
    "    ### Preprocess data\n",
    "    _target, _label_names, _data = preprocess_dataset(_df\n",
    "                                                  , _description\n",
    "                                                  , scaler = _scaler\n",
    "                                                  , sampler = _sampler\n",
    "                                                  , verbose = _verbose\n",
    "                                                 )\n",
    "    \n",
    "    ### Train a (single) SOM - from MiniSom documentation\n",
    "    som = MiniSom(x = N_NEURONS \n",
    "                  , y = M_NEURONS \n",
    "                  , input_len = _data.shape[1] # int: Number of the elements of the vectors in input.\n",
    "                  , sigma = SIGMA \n",
    "                  , learning_rate = LEARNING_RATE \n",
    "                 #, decay_function = asymptotic_decay  # Need to understand this still learning_rate / (1+t/(max_iterarations/2))\n",
    "                  , neighborhood_function = NEIGHBORHOOD_FUNCTION \n",
    "                  , topology = TOPOLOGY\n",
    "                  , activation_distance = ACTIVATION_DISTANCE\n",
    "                  , random_seed = RANDOM_SEED\n",
    "                 )\n",
    "\n",
    "    som.pca_weights_init(_data)\n",
    "    som.train(_data\n",
    "              , num_iteration = NUM_ITERATIONS\n",
    "              , random_order = RANDOM_ORDER  \n",
    "              , verbose=_verbose\n",
    "             )  # random training\n",
    "    \n",
    "    # Reformat data for SMToolbox structure\n",
    "    weights = som._weights.reshape(-1, 24)       # weights['arr']\n",
    "    n_neurons = N_NEURONS                        # weights['xdim']\n",
    "    m_neurons = M_NEURONS                        # weights['ydim']\n",
    "    dimension = _data.shape[1]                    # weights['vec_dim']\n",
    "    classes = _target                             # classes['arr']\n",
    "    component_names = list(_label_names.values()) # classes['classes_names']\n",
    "    data = _data                                  # idata['arr']    \n",
    "    \n",
    "    # Pack files to a pickle\n",
    "    with open(EXPERIMENT_DATA_FOLDER + '/TRAINED_SOM_DATA_' + _description + '.pkl', 'wb') as f:\n",
    "        pickle.dump([weights, n_neurons, m_neurons, dimension, classes, component_names, data], f)\n",
    "    \n",
    "    ### Use SOMToolbox on our newly generated SOM\n",
    "    sm = SOMToolbox(weights = weights\n",
    "                    , m = m_neurons\n",
    "                    , n = n_neurons\n",
    "                    , dimension = dimension\n",
    "                    , input_data = data\n",
    "                    , classes = classes\n",
    "                    #, component_names = component_names\n",
    "                   )\n",
    "    \n",
    "    #return _target, _label_names, _data\n",
    "    return weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85430788",
   "metadata": {},
   "source": [
    "#### Define static visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HitHistogram\n",
    "def HitHist(_m, _n, _weights, _idata):\n",
    "    hist = np.zeros(_m * _n)\n",
    "    for vector in _idata: \n",
    "        position =np.argmin(np.sqrt(np.sum(np.power(_weights - vector, 2), axis=1)))\n",
    "        hist[position] += 1\n",
    "\n",
    "    return hist.reshape(_m, _n)\n",
    "\n",
    "#U-Matrix - implementation\n",
    "def UMatrix(_m, _n, _weights, _dim):\n",
    "    U = _weights.reshape(_m, _n, _dim)\n",
    "    U = np.insert(U, np.arange(1, _n), values=0, axis=1)\n",
    "    U = np.insert(U, np.arange(1, _m), values=0, axis=0)\n",
    "    #calculate interpolation\n",
    "    for i in range(U.shape[0]): \n",
    "        if i%2==0:\n",
    "            for j in range(1,U.shape[1],2):\n",
    "                U[i,j][0] = np.linalg.norm(U[i,j-1] - U[i,j+1], axis=-1)\n",
    "        else:\n",
    "            for j in range(U.shape[1]):\n",
    "                if j%2==0: \n",
    "                    U[i,j][0] = np.linalg.norm(U[i-1,j] - U[i+1,j], axis=-1)\n",
    "                else:      \n",
    "                    U[i,j][0] = (np.linalg.norm(U[i-1,j-1] - U[i+1,j+1], axis=-1) + np.linalg.norm(U[i+1,j-1] - U[i-1,j+1], axis=-1))/(2*np.sqrt(2))\n",
    "\n",
    "    U = np.sum(U, axis=2) #move from Vector to Scalar\n",
    "\n",
    "    for i in range(0, U.shape[0], 2): #count new values\n",
    "        for j in range(0, U.shape[1], 2):\n",
    "            region = []\n",
    "            if j>0: region.append(U[i][j-1]) #check left border\n",
    "            if i>0: region.append(U[i-1][j]) #check bottom\n",
    "            if j<U.shape[1]-1: region.append(U[i][j+1]) #check right border\n",
    "            if i<U.shape[0]-1: region.append(U[i+1][j]) #check upper border\n",
    "\n",
    "            U[i,j] = np.median(region)\n",
    "\n",
    "    return U\n",
    "\n",
    "#SDH - implementation\n",
    "def SDH(_m, _n, _weights, _idata, factor, approach):\n",
    "    import heapq\n",
    "\n",
    "    sdh_m = np.zeros( _m * _n)\n",
    "\n",
    "    cs=0\n",
    "    for i in range(factor): cs += factor-i\n",
    "\n",
    "    for vector in _idata:\n",
    "        dist = np.sqrt(np.sum(np.power(_weights - vector, 2), axis=1))\n",
    "        c = heapq.nsmallest(factor, range(len(dist)), key=dist.__getitem__)\n",
    "        if (approach==0): # normalized\n",
    "            for j in range(factor):  sdh_m[c[j]] += (factor-j)/cs \n",
    "        if (approach==1):# based on distance\n",
    "            for j in range(factor): sdh_m[c[j]] += 1.0/dist[c[j]] \n",
    "        if (approach==2): \n",
    "            dmin, dmax = min(dist[c]), max(dist[c])\n",
    "            for j in range(factor): sdh_m[c[j]] += 1.0 - (dist[c[j]]-dmin)/(dmax-dmin)\n",
    "\n",
    "    return sdh_m.reshape(_m, _n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description):\n",
    "    hithist = hv.Image(HitHist(m_neurons\n",
    "                               , m_neurons\n",
    "                               , weights\n",
    "                               , data\n",
    "                              )\n",
    "                      ).opts(xaxis=None, yaxis=None) \n",
    "\n",
    "    um = hv.Image(UMatrix(m_neurons\n",
    "                          , m_neurons\n",
    "                          , weights\n",
    "                          , 24 # ??? was 4 - Dimensions?\n",
    "                         )\n",
    "                 ).opts(xaxis=None, yaxis=None) \n",
    "\n",
    "    sdh = hv.Image(SDH(m_neurons\n",
    "                       , m_neurons\n",
    "                       , weights\n",
    "                       , data \n",
    "                       , 25 #??? Don't know \n",
    "                       , 0 # ?? Dont know\n",
    "                      )\n",
    "                  ).opts(xaxis=None, yaxis=None)   \n",
    "\n",
    "    allthree =  hv.Layout([hithist.relabel('HitHist').opts(cmap='kr')\n",
    "                           , um.relabel('U-Matrix').opts(cmap='jet')\n",
    "                           , sdh.relabel('SDH').opts(cmap='viridis')\n",
    "                          ]\n",
    "                         )\n",
    "    #display(allthree)\n",
    "    \n",
    "    #hv.save(hithist, filename=\"plot.png\", fmt=\"png\")\n",
    "    display(hithist.relabel('HitHist').opts(cmap='kr'))\n",
    "    display(um.relabel('U-Matrix').opts(cmap='jet'))\n",
    "    display(sdh.relabel('SDH').opts(cmap='viridis'))\n",
    "    \n",
    "    print(\"FIGURE OUT HOW TO SAVE THESE PLOTS!?!?!?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92cf01",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable for SomToolbox\n",
    "## Awesome for understanding, but very memory intensive\n",
    "INTERACTIVE_EXPLORATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb49de",
   "metadata": {},
   "source": [
    "## Without oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7c6a6",
   "metadata": {},
   "source": [
    "### E01) Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca95e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e01_nonsampled_unscaled'\n",
    "scaler = None\n",
    "sampler = None\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d5b59-02ab-469f-89c2-1678c0daad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e68051a",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9afcc6",
   "metadata": {},
   "source": [
    "### E02) Using Min-Max-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e02_nonsampled_MinMax'\n",
    "scaler = MinMaxScaler()\n",
    "sampler = None\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9a152-962b-47c6-aabd-eb2c183f9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c903f073",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111b567",
   "metadata": {},
   "source": [
    "### E03) Using Zero mean Unit Variance Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed39ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e03_nonsampled_ZeroMeanUnitVariance'\n",
    "scaler = StandardScaler(with_mean = False)\n",
    "sampler = None\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610d2e0-7319-42f6-93d6-e5288183187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8d5cdff",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a86dd",
   "metadata": {},
   "source": [
    "### E04) Using Z-Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721557c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e04_nonsampled_ZScaling'\n",
    "scaler = StandardScaler(with_mean = True)\n",
    "sampler = None\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f37e42-c0e9-40e8-aed8-68647d0e00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd78272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "526bc897",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec7c6b",
   "metadata": {},
   "source": [
    "### E05) Using Max-Abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e05_nonsampled_MaxAbs'\n",
    "scaler = MaxAbsScaler()\n",
    "sampler = None\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b066651-f6bb-4cb3-9399-bb03d093cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ac8a117",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c42a7",
   "metadata": {},
   "source": [
    "### E06) Using Robust-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04396f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e06_nonsampled_Robust'\n",
    "scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0))\n",
    "sampler = None\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4036b-3668-47ce-8c12-e362cd5ce424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff06642-390e-4524-a16e-7c8ebc7db2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fd4c7aa-dc62-498f-9c60-8de10a669552",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2ae2b",
   "metadata": {},
   "source": [
    "## With oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a7b80",
   "metadata": {},
   "source": [
    "### E07) Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c704fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e07_smote_unscaled'\n",
    "scaler = None\n",
    "sampler = SMOTE(random_state = 42)\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2da4fe-834a-4134-a7a4-0ee716ae2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a353250",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf1d71",
   "metadata": {},
   "source": [
    "### E08) Using Min-Max-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e08_smote_MinMax'\n",
    "scaler = MinMaxScaler()\n",
    "sampler = SMOTE(random_state = 42)\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9aa70-c798-44be-81f8-6a74759f1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3706b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b19776f5",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8efce2",
   "metadata": {},
   "source": [
    "### E09) Using Zero mean Unit Variance Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffd200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e09_smote_ZeroMeanUnitVariance'\n",
    "scaler = StandardScaler(with_mean = False)\n",
    "sampler = SMOTE(random_state = 42)\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c5d59-831f-4114-bf50-52c49ed9e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd14496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0c81a3b",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb8d864",
   "metadata": {},
   "source": [
    "### E10) Using Z-Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e10_smote_ZScaling'\n",
    "scaler = StandardScaler(with_mean = True)\n",
    "sampler = SMOTE(random_state = 42)\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178eaa84-01d0-482d-be55-5a9913a8ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90027e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d17a35b0",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2dd01a",
   "metadata": {},
   "source": [
    "### E11) Using Max-Abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e11_smote_MaxAbs'\n",
    "scaler = MaxAbsScaler()\n",
    "sampler = SMOTE(random_state = 42)\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97477fb6-7f91-45a9-bc51-ea19fb2afde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab028e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e8895d8",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390becd",
   "metadata": {},
   "source": [
    "### E12) Using Robust-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c00532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Experiment \"parameters\"\n",
    "experiment_description = 'e12_nonsampled_Robust'\n",
    "scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0))\n",
    "sampler = SMOTE(random_state = 42)\n",
    "\n",
    "# Preprocess and train\n",
    "weights, n_neurons, m_neurons, dimension, classes, component_names, data, sm = train_som(df\n",
    "                                                                                      , _description = experiment_description\n",
    "                                                                                      , _scaler = scaler\n",
    "                                                                                      , _sampler = sampler\n",
    "                                                                                      , _verbose = True\n",
    "                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d98243-975f-40f5-94d9-5b9783c73638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do entire preprocessing again, and save in correct java folder\n",
    "target, label_names, data = preprocess_dataset(df, description = experiment_description, scaler = scaler, sampler = sampler, verbose = False)\n",
    "javafy_data(target, label_names, data, experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive exploration\n",
    "if INTERACTIVE_EXPLORATION:\n",
    "    display(sm._mainview)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfdd4239",
   "metadata": {},
   "source": [
    "# Generate (and save?) static plots\n",
    "generate_visualizations(weights, n_neurons, m_neurons, dimension, classes, component_names, data, description = experiment_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c58927",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "**Frick If I know**\n",
    "\n",
    "**Remaining Todo:**\n",
    "  * Generate more statics\n",
    "  * Figure out how to save statics"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f725c89-e38d-4510-a06e-0c094dc8c968",
   "metadata": {},
   "source": [
    "# There was an attempt...\n",
    "print(sm._visualizations[1]._main.__dict__.keys())\n",
    "print(sm._visualizations[1]._main._controls.__dict__.keys())\n",
    "print(sm._visualizations[1]._main._controls._callbacks)\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1].__dict__.keys())\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1]._callbacks)\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1]._start_param_value)\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1]._end_param_value)\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1].__dict__)\n",
    "sm._visualizations[1]._main._controls._objects_param_value[0][0][1]._value_param_value = 2\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1]._value_param_value)\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1]._callbacks[1])\n",
    "print(sm._visualizations[1]._main._controls._objects_param_value[0][0][1]._value_param_value)\n",
    "print(sm._visualizations[1]._main._controls._parameters_state)\n",
    "print(sm._visualizations[1]._main._controls)\n",
    "print(sm._visualizations[1]._main._Image._callback_param_value)\n",
    "display(sm._visualizations[2]._main._Image)#.callback(3))\n",
    "print(sm._visualizations[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
